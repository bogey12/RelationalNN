{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RelationalNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0INlVBL3CA4o",
        "colab_type": "text"
      },
      "source": [
        "## Connect Google Drive to Collab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVX-SGxHbXNE",
        "colab_type": "code",
        "outputId": "a1395ac2-3a8c-42d5-a42b-7b48cf15b3aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0WH8H3jCHb4",
        "colab_type": "text"
      },
      "source": [
        "## Generate Sort-of-Clevr Dataset (taken from https://github.com/kimhc6028/relational-networks)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2J_0MKZZND0W",
        "colab_type": "code",
        "outputId": "f63d5ba8-2552-4bfd-b248-4b4e34b5fd84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "#import cPickle as pickle\n",
        "import pickle\n",
        "\n",
        "train_size = 9800\n",
        "test_size = 200\n",
        "img_size = 75\n",
        "size = 5\n",
        "question_size = 11 ##6 for one-hot vector of color, 2 for question type, 3 for question subtype\n",
        "\"\"\"Answer : [yes, no, rectangle, circle, r, g, b, o, k, y]\"\"\"\n",
        "\n",
        "nb_questions = 10\n",
        "dirs = './data'\n",
        "\n",
        "colors = [\n",
        "    (0,0,255),##r\n",
        "    (0,255,0),##g\n",
        "    (255,0,0),##b\n",
        "    (0,156,255),##o\n",
        "    (128,128,128),##k\n",
        "    (0,255,255)##y\n",
        "]\n",
        "\n",
        "\n",
        "try:\n",
        "    os.makedirs(dirs)\n",
        "except:\n",
        "    print('directory {} already exists'.format(dirs))\n",
        "\n",
        "def center_generate(objects):\n",
        "    while True:\n",
        "        pas = True\n",
        "        center = np.random.randint(0+size, img_size - size, 2)        \n",
        "        if len(objects) > 0:\n",
        "            for name,c,shape in objects:\n",
        "                if ((center - c) ** 2).sum() < ((size * 2) ** 2):\n",
        "                    pas = False\n",
        "        if pas:\n",
        "            return center\n",
        "\n",
        "\n",
        "\n",
        "def build_dataset():\n",
        "    objects = []\n",
        "    img = np.ones((img_size,img_size,3)) * 255\n",
        "    for color_id,color in enumerate(colors):  \n",
        "        center = center_generate(objects)\n",
        "        if random.random()<0.5:\n",
        "            start = (center[0]-size, center[1]-size)\n",
        "            end = (center[0]+size, center[1]+size)\n",
        "            cv2.rectangle(img, start, end, color, -1)\n",
        "            objects.append((color_id,center,'r'))\n",
        "        else:\n",
        "            center_ = (center[0], center[1])\n",
        "            cv2.circle(img, center_, size, color, -1)\n",
        "            objects.append((color_id,center,'c'))\n",
        "\n",
        "\n",
        "    rel_questions = []\n",
        "    norel_questions = []\n",
        "    rel_answers = []\n",
        "    norel_answers = []\n",
        "    \"\"\"Non-relational questions\"\"\"\n",
        "    for _ in range(nb_questions):\n",
        "        question = np.zeros((question_size))\n",
        "        color = random.randint(0,5)\n",
        "        question[color] = 1\n",
        "        question[6] = 1\n",
        "        subtype = random.randint(0,2)\n",
        "        question[subtype+8] = 1\n",
        "        norel_questions.append(question)\n",
        "        \"\"\"Answer : [yes, no, rectangle, circle, r, g, b, o, k, y]\"\"\"\n",
        "        if subtype == 0:\n",
        "            \"\"\"query shape->rectangle/circle\"\"\"\n",
        "            if objects[color][2] == 'r':\n",
        "                answer = 2\n",
        "            else:\n",
        "                answer = 3\n",
        "\n",
        "        elif subtype == 1:\n",
        "            \"\"\"query horizontal position->yes/no\"\"\"\n",
        "            if objects[color][1][0] < img_size / 2:\n",
        "                answer = 0\n",
        "            else:\n",
        "                answer = 1\n",
        "\n",
        "        elif subtype == 2:\n",
        "            \"\"\"query vertical position->yes/no\"\"\"\n",
        "            if objects[color][1][1] < img_size / 2:\n",
        "                answer = 0\n",
        "            else:\n",
        "                answer = 1\n",
        "        norel_answers.append(answer)\n",
        "    \n",
        "    \"\"\"Relational questions\"\"\"\n",
        "    for i in range(nb_questions):\n",
        "        question = np.zeros((question_size))\n",
        "        color = random.randint(0,5)\n",
        "        question[color] = 1\n",
        "        question[7] = 1\n",
        "        subtype = random.randint(0,2)\n",
        "        question[subtype+8] = 1\n",
        "        rel_questions.append(question)\n",
        "\n",
        "        if subtype == 0:\n",
        "            \"\"\"closest-to->rectangle/circle\"\"\"\n",
        "            my_obj = objects[color][1]\n",
        "            dist_list = [((my_obj - obj[1]) ** 2).sum() for obj in objects]\n",
        "            dist_list[dist_list.index(0)] = 999\n",
        "            closest = dist_list.index(min(dist_list))\n",
        "            if objects[closest][2] == 'r':\n",
        "                answer = 2\n",
        "            else:\n",
        "                answer = 3\n",
        "                \n",
        "        elif subtype == 1:\n",
        "            \"\"\"furthest-from->rectangle/circle\"\"\"\n",
        "            my_obj = objects[color][1]\n",
        "            dist_list = [((my_obj - obj[1]) ** 2).sum() for obj in objects]\n",
        "            furthest = dist_list.index(max(dist_list))\n",
        "            if objects[furthest][2] == 'r':\n",
        "                answer = 2\n",
        "            else:\n",
        "                answer = 3\n",
        "\n",
        "        elif subtype == 2:\n",
        "            \"\"\"count->1~6\"\"\"\n",
        "            my_obj = objects[color][2]\n",
        "            count = -1\n",
        "            for obj in objects:\n",
        "                if obj[2] == my_obj:\n",
        "                    count +=1 \n",
        "            answer = count+4\n",
        "\n",
        "        rel_answers.append(answer)\n",
        "\n",
        "    relations = (rel_questions, rel_answers)\n",
        "    norelations = (norel_questions, norel_answers)\n",
        "    \n",
        "    img = img/255.\n",
        "    dataset = (img, relations, norelations)\n",
        "    return dataset\n",
        "\n",
        "\n",
        "print('building test datasets...')\n",
        "test_datasets = [build_dataset() for _ in range(test_size)]\n",
        "print('building train datasets...')\n",
        "train_datasets = [build_dataset() for _ in range(train_size)]\n",
        "\n",
        "\n",
        "#img_count = 0\n",
        "#cv2.imwrite(os.path.join(dirs,'{}.png'.format(img_count)), cv2.resize(train_datasets[0][0]*255, (512,512)))\n",
        "\n",
        "\n",
        "print('saving datasets...')\n",
        "filename = os.path.join(dirs,'sort-of-clevr.pickle')\n",
        "with  open(filename, 'wb') as f:\n",
        "    pickle.dump((train_datasets, test_datasets), f)\n",
        "print('datasets saved at {}'.format(filename))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "building test datasets...\n",
            "building train datasets...\n",
            "saving datasets...\n",
            "datasets saved at ./data/sort-of-clevr.pickle\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "maEUizNuBKSF",
        "colab_type": "text"
      },
      "source": [
        "## Define functions for neural network + data processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yN3gQZtwA4VS",
        "colab_type": "code",
        "outputId": "ea183ff4-6952-438b-d0d1-e302ad73db62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "import keras\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pickle\n",
        "import os\n",
        "import gc\n",
        "import os\n",
        "from google.colab import files\n",
        "from PIL import Image\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "\n",
        "#mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
        "'''TO DO: Create LSTM for processing questions\n",
        "   - Load and test with sort-of-clevr database\n",
        "   \n",
        "   - IDEA: Instead of taking every object pair, instead use random object pairs and instead of reduce mean,\n",
        "   concatenate the object pairs together after feeding it through the object pair neural net (g(x))\n",
        "\n",
        "- Issue probably stems from the information lost from reduce mean \n",
        "- Majority ram used in initial loading and processing data in memory\n",
        "- Doesnt work for minibatch training\n",
        "'''\n",
        "\n",
        "'''LSTM Setup: Words are given unique integers (one hot encoding) - questions are fed in one word at a time'''\n",
        "'''Or For simplicity - just add question vector directly to RN vector ie \n",
        "Questions are encoded into a vector of size of 11 : 6 for one-hot vector \n",
        "for certain color among 6 colors, 2 for one-hot vector of \n",
        "relational/non-relational questions. 3 for one-hot vector of 3 subtypes.'''\n",
        "\n",
        "def weight_variable(shape,namez):\n",
        "  initial = tf.truncated_normal(shape, stddev=0.1,name=namez)\n",
        "  return tf.Variable(initial)\n",
        "\n",
        "def bias_variable(shape,namez):\n",
        "  initial = tf.constant(0.1, shape=shape,name=namez)\n",
        "  return tf.Variable(initial)\n",
        "\n",
        "def lstm_cell(lstm_size):\n",
        "  return tf.keras.layers.LSTM(lstm_size)\n",
        "\n",
        "def conv2d(x, W, namez):\n",
        "  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME',name=namez)\n",
        "\n",
        "def max_pool_2x2(x):\n",
        "  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
        "                        strides=[1, 2, 2, 1], padding='SAME')\n",
        "\n",
        "def getarray(imgw):\n",
        "\tim = Image.open(imgw)\n",
        "\tnpim = np.array(im)\n",
        "\tnpim = npim.reshape(-1,80,80,4)\n",
        "\treturn npim\n",
        "\n",
        "def getarraystandard(imgw):\n",
        "\tnpim = getarray(imgw)\n",
        "\n",
        "\tscalar = StandardScaler()\n",
        "\n",
        "\tshape = npim.shape\n",
        "\tnpim = npim.reshape(1,-1)\n",
        "\n",
        "\tnpim = scalar.fit_transform(npim)\n",
        "\n",
        "\tnpim = npim.reshape(shape)\n",
        "\n",
        "\treturn npim\n",
        "\n",
        "def loadclvr():\n",
        "\tprint('loading data...')\n",
        "\tdirs = './data'\n",
        "\tfilename = os.path.join(dirs,'sort-of-clevr.pickle')\n",
        "\twith open(filename,'rb') as f:\n",
        "\t\ttraindata, testdata = pickle.load(f)\n",
        "\treltrain = []\n",
        "\treltest = []\n",
        "\tnoreltrain = []\n",
        "\tnoreltest = []\n",
        "\tprint('processing data...')\n",
        "\n",
        "\tfor img, relations, norelations in traindata:\n",
        "\t\timg = np.swapaxes(img,0,2)\n",
        "\t\tfor qst,ans in zip(relations[0], relations[1]):\n",
        "\t\t\treltrain.append((img,qst,ans))\n",
        "\t\tfor qst,ans in zip(norelations[0],norelations[1]):\n",
        "\t\t\tnoreltrain.append((img,qst,ans))\n",
        "\n",
        "\tfor img, relations, norelations in testdata:\n",
        "\t\timg = np.swapaxes(img,0,2)\n",
        "\t\tfor qst,ans in zip(relations[0], relations[1]):\n",
        "\t\t\treltest.append((img,qst,ans))\n",
        "\t\tfor qst,ans in zip(norelations[0], norelations[1]):\n",
        "\t\t\tnoreltest.append((img,qst,ans))\n",
        "\n",
        "\treturn (reltrain, reltest, noreltrain, noreltest)\n",
        "\n",
        "def cvt_data_axis(data):\n",
        "\timg = [e[0] for e in data]\n",
        "\tqst = [e[1] for e in data]\n",
        "\tans = [e[2] for e in data]\n",
        "\treturn (img,qst,ans)\n",
        "\n",
        "def processclvr(data):\n",
        "\timgs = np.asarray(data[0])\n",
        "\tquestions = np.asarray(data[1])\n",
        "\n",
        "\tanswers = np.asarray([data[2]])\n",
        "\tanswers = answers.reshape(98000,1)\n",
        "\tonehot = OneHotEncoder(categories=[np.array([0,1,2,3,4,5,6,7,8,9])])\n",
        "\tanswers = onehot.fit_transform(answers)\n",
        "\n",
        "\treturn (imgs,questions,answers)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ul2JRPCOBYch",
        "colab_type": "text"
      },
      "source": [
        "## Load and Process Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKxcX6gSBHjV",
        "colab_type": "code",
        "outputId": "9edfcfe1-62d0-4129-b29e-5fb4fa57e97a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#files.download( \"data/sort-of-clevr.pickle\" ) \n",
        "reltrain,reltest,noreltrain,noreltest = loadclvr()\n",
        "del(reltest)\n",
        "del(noreltrain)\n",
        "del(noreltest)\n",
        "gc.collect()\n",
        "\n",
        "a = cvt_data_axis(reltrain)\n",
        "\n",
        "reltrain = processclvr(a)\n",
        "qsts = reltrain[1][0].reshape(1,-1)\n",
        "print(qsts.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading data...\n",
            "processing data...\n",
            "(1, 11)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7cNTkPoBeSl",
        "colab_type": "text"
      },
      "source": [
        "## Initialize Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27vWxtzf-tUs",
        "colab_type": "code",
        "outputId": "b2b1a2a8-d424-4f91-c887-adb0b2b15057",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "\n",
        "#npim = getarraystandard('test.tiff')\n",
        "#npim2 = getarraystandard('test2.tiff')\n",
        "\n",
        "#finnpim = np.concatenate((npim,npim2),axis=0)\n",
        "\n",
        "'''LSTM Word Processor'''\n",
        "#xq = tf.placeholder(tf.float32, [None, n1,n2],name='xq')\n",
        "#split input question into individual word vectors\n",
        "#xq = tf.split(xq,n1,1)\n",
        "\n",
        "#w1 = lstm_cell(n2)\n",
        "#outputs, states = \n",
        "\n",
        "'''CNN Archetecture: 4 Conv layers to k feature maps of size nxn\n",
        "k is the number ofk ernels of the final conv layer'''\n",
        "#Image Size 80x80 with 5 pixel shapes\n",
        "x = tf.placeholder(tf.float32, [None, 16875],name='x')\n",
        "y_ = tf.placeholder(tf.float32, [None, 10], name='y_')\n",
        "\n",
        "'''Conv Network'''\n",
        "#First Convolutional Layer\n",
        "W_conv1 = weight_variable([3, 3, 3, 32],'W_conv1')\n",
        "b_conv1 = bias_variable([32],'b_conv1')\n",
        "\n",
        "x_image = tf.reshape(x, [-1,75,75,3])\n",
        "\n",
        "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1,'h_conv1') + b_conv1)\n",
        "h_pool1 = max_pool_2x2(h_conv1)\n",
        "\n",
        "#Second Convolutional Layer\n",
        "W_conv2 = weight_variable([3, 3, 32, 32],'W_conv2')\n",
        "b_conv2 = bias_variable([32],'b_conv2')\n",
        "\n",
        "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2,'h_conv2') + b_conv2)\n",
        "h_pool2 = max_pool_2x2(h_conv2)\n",
        "\n",
        "#Third Convolutional Layer\n",
        "W_conv3 = weight_variable([3, 3, 32, 32],'W_conv3')\n",
        "b_conv3 = bias_variable([32],'b_conv3')\n",
        "\n",
        "blah = tf.nn.relu(conv2d(h_pool2, W_conv3,'blah') + b_conv3)\n",
        "h_conv3 = max_pool_2x2(blah)\n",
        "\"h_conv3 size: [None , 4 ,4 , 64] \"\n",
        "\n",
        "\n",
        "#Fourth Convolutional Layer\n",
        "W_conv4 = weight_variable([3, 3, 32, 32],'W_conv4')\n",
        "b_conv4 = bias_variable([32],'b_conv4')\n",
        "\n",
        "h_conv4 = tf.nn.relu(conv2d(h_conv3, W_conv4,'h_conv4') + b_conv4)\n",
        "h_pool4 = max_pool_2x2(h_conv4)\n",
        "#print(h_pool4)\n",
        "\n",
        "\n",
        "with tf.Session() as sess:\n",
        "\tsess.run(tf.global_variables_initializer())\n",
        "\n",
        "#Output (Batch, New COl, New Rows, Filters)\n",
        "#Get Objects (there are col * rows objects)\n",
        "\tobjects = []\n",
        "\t'''REMEMBER TO CHANGE OUTPUT WHEN SWTICHING BETWEEN MNIST AND ACTUAL DATA'''\n",
        "\tbatchx = (np.swapaxes(reltrain[0][0],0,2))\n",
        "\toutput = sess.run(h_pool4, feed_dict={x: batchx.reshape(1,-1)})\n",
        "\t#output = sess.run(h_pool4, feed_dict={x: npim})\n",
        "\t#print(h_pool3)\n",
        "\t\n",
        "\t'''Output (h_pool4) shape: (-1,3,3,32)'''\n",
        "\tprint(output.shape)\n",
        "\t\n",
        "\tfor i in range(0,len(output[0])):\n",
        "\t\tfor j in range(0,len(output[0,0])):\n",
        "\t\t\tobjects += [tf.concat([h_pool4[:,i,j,:], [[((5*i + j) / 25)]]], axis=1)]\n",
        "\tobjects = np.asarray(objects)\n",
        "\tprint(objects[0].shape)\n",
        "#Compare each object pair\n",
        "\tqst_ = tf.placeholder(tf.float32, [None,11] ,name='qst_')\n",
        "\t#Stack object pairs into batch\n",
        "\tcheck = -1\n",
        "\tfor k in range(0,len(objects)):\n",
        "\t\tfirst = objects[k]\n",
        "\t\tfor g in range(k+1,len(objects)):\n",
        "\t\t\tsecond = objects[g]\n",
        "\t\t\tif check == -1:\n",
        "\t\t\t\tinput2 = tf.concat((first,second,qst_), axis=1)\n",
        "\n",
        "\t\t\t\tcheck = 0\n",
        "\t\t\telse:\n",
        "\t\t\t\ttempinput2 = tf.concat((first,second,qst_), axis=1)\n",
        "\t\t\t\tinput2 = tf.concat((input2,tempinput2),axis=0)\n",
        "\t\t\t\t#print(input2)\n",
        "\t'''Input 2 (Stacked Object Pairs) shape: (300, 77)'''\n",
        "\tprint('INPUT 2 BElOW')\n",
        "\tprint(input2)\n",
        "\t'''First MLP (For object pairs)'''\n",
        "\t#x2 = tf.placeholder(tf.float32, [None,128],name='x2')\n",
        "\n",
        "\tW_21 = weight_variable([77,66],'W_21')\n",
        "\tb_21 = bias_variable([66],'b_21')\n",
        "\n",
        "\th21 = tf.nn.relu(tf.matmul(input2,W_21) + b_21)\n",
        "\n",
        "\tW_22 = weight_variable([66,66],'W_22')\n",
        "\tb_22 = bias_variable([66],'b_22')\n",
        "\n",
        "\th22 = tf.nn.relu(tf.matmul(h21,W_22) + b_22)\n",
        "\n",
        "\tW_23 = weight_variable([66,66],'W_23')\n",
        "\tb_23 = bias_variable([66],'b_23')\n",
        "\n",
        "\th23 = tf.nn.relu(tf.matmul(h22,W_23) + b_23)\n",
        "\n",
        "\tW_24 = weight_variable([66,128],'W_24')\n",
        "\tb_24 = bias_variable([128],'b_24')\n",
        "\n",
        "\tdrop = tf.placeholder(tf.float32)\n",
        "\n",
        "\th244 = tf.nn.relu(tf.matmul(h23,W_24) + b_24)\n",
        "\th24 = tf.nn.dropout(h244, keep_prob = drop)\n",
        "\n",
        "\t'''h24 shape: (300, 128)'''\n",
        "\t#Feed batch of object pairs into First Relational MLP\n",
        "\t#output2 = sess.run(h24, feed_dict={x2: sess.run(input2,feed_dict={x: npim})})\n",
        "\t#print(output2.shape)\n",
        "\n",
        "\t#Elementwise sum of all object pair outputs\n",
        "\tinput3old = tf.reduce_mean(h24,axis=0)\t\n",
        "\tinput3 = tf.reshape(input3old,[-1,128])\n",
        "\t'''Second MLP'''\n",
        "\t#x3 = tf.placeholder(tf.float32,[None,128],name='x3')\n",
        "\n",
        "\tW_31 = weight_variable([128,64],'W_31')\n",
        "\tb_31 = bias_variable([64],'W_31')\n",
        "\ttestsimple = tf.layers.flatten(h_conv3)\n",
        "\th31 = tf.nn.relu(tf.matmul(input3,W_31) + b_31)\n",
        "\n",
        "\t#Output Layer size equal to answer vocabulary length (one-shot encoding)\n",
        "\t\n",
        "\n",
        "\tE_31 = weight_variable([64,64],'E_31')\n",
        "\tbe_31 = bias_variable([64],'be_31')\n",
        "\th322 = tf.nn.relu(tf.matmul(h31,E_31) + be_31)\n",
        "\th32 = tf.nn.dropout(h322, keep_prob = drop)\n",
        "\n",
        "\tW_32 = weight_variable([64,10],'W_32')\n",
        "\tb_32 = bias_variable([10],'b_32')\n",
        "\n",
        "\tfinaloutt = tf.matmul(h32,W_32) + b_32\n",
        "\tfinalout = tf.nn.dropout(finaloutt, keep_prob = drop)\n",
        "\n",
        "\t#Feed into second relational MLP\n",
        "\t\n",
        "\t#print(sess.run(finalout, feed_dict={x: finnpim}))\n",
        "\n",
        "\t#Training\n",
        "\t\n",
        "\terror = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=finalout))\n",
        "\ttrain_step = tf.train.AdamOptimizer(1e-4).minimize(error)\n",
        "\tcorrect_prediction = tf.equal(tf.argmax(finalout,1), tf.argmax(y_,1))\n",
        "\taccuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "\tsess.run(tf.global_variables_initializer())\n",
        "\tsaver = tf.train.Saver()\n",
        "\t#save_path = saver.save(sess, \"/content/drive/My Drive/RelationalNN/dm.ckpt\")\n",
        "\t#print('done saving at',save_path)\n",
        "\t#for file in os.listdir('cpt'):\n",
        "\t\t#path = os.path.join('cpt/',file)\n",
        "\t\t#files.download(path)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 5, 5, 32)\n",
            "(1, 33)\n",
            "INPUT 2 BElOW\n",
            "Tensor(\"concat_3119:0\", shape=(300, 77), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZ6Vivn-Bkp5",
        "colab_type": "text"
      },
      "source": [
        "## Restore saved model if available and start training Relational CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUMHM9BN_Lso",
        "colab_type": "code",
        "outputId": "7b91df77-08be-4e23-f7b5-4b6e043df141",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import os\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pickle\n",
        "import os\n",
        "import gc\n",
        "import os\n",
        "from google.colab import files\n",
        "from PIL import Image\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "from google.colab import files\n",
        "\n",
        "with tf.Session() as sess: \n",
        "\t#saver = tf.train.Saver()\n",
        "\tsess.run(tf.global_variables_initializer())\n",
        "\tprint(sess.run(b_32))\n",
        "\tsaver.restore(sess,'/content/drive/My Drive/RelationalNN/dm1.ckpt')\n",
        "\tprint(sess.run(b_32))\n",
        "\tfor k in range(1,130):\n",
        "\t\tprint('EPOCH %d' % (k))\n",
        "\t\t#idx = np.random.permutation(len(reltrain[2].toarray()))\n",
        "\t\tlabelz,qstz,dataz = reltrain[2], reltrain[1], reltrain[0]\n",
        "\t\tif k % 5 == 0:\n",
        "\t\t\tsess.run(tf.global_variables_initializer())\n",
        "\t\t\tsaver = tf.train.Saver()\n",
        "\t\t\tsave_path = saver.save(sess, \"/content/drive/My Drive/RelationalNN/dm%d.ckpt\" % (k))\n",
        "\t\t\tprint('done saving at',save_path)\n",
        "\t\taccsum = 0\n",
        "\t\tfor i in range(0,75000):\n",
        "\t\t\t#print(type(reltrain[2][i].reshape(1,-1)))\n",
        "\t\t\tys = labelz[i].toarray()\n",
        "\t\t\tqsts = qstz[i].reshape(1,-1)\n",
        "\t\t\tbatchx = (np.swapaxes(dataz[i],0,2))\n",
        "\t\t\t#print(ys)\n",
        "\t\t\t#print(qsts)\n",
        "\t\t\t\n",
        "\t\t\ttrain_step.run(feed_dict={x: batchx.reshape(1,-1), y_: ys, qst_: qsts,drop: 1})\n",
        "\t\t\t'''\n",
        "\t\t\tif grads = -1:\n",
        "\t\t\t\tgrads = optimizer.compute_gradients(error, feed_dict={x: batchx.reshape(1,-1), y_: ys, qst_: qsts,drop: 0.5})\n",
        "\t\t\telse:\n",
        "\t\t\t\ttemp = optimizer.compute_gradients(error, feed_dict={x: batchx.reshape(1,-1), y_: ys, qst_: qsts,drop: 0.5})\n",
        "\t\t\t\tfor i in range(0,len(temp)):\n",
        "\t\t\t\t\tgrads[i][1] += temp[i][1] / 30\n",
        "\t\t\t\tif i % 30 == 0:\n",
        "\t\t\t\t\toptimizer.apply_gradients(grads)\n",
        "\t\t\t\t\tgrads = -1\n",
        "\t\t\t'''\n",
        "\n",
        "\n",
        "\t\t\tif i % 10 == 0:\n",
        "\t\t\t\tprint(sess.run(b_32))\n",
        "\t\t\t\t#batch = mnist.train.next_batch(100)\n",
        "\t\t\t\ttrain_accuracy = accuracy.eval(feed_dict={\n",
        "\t\t\t\t\tx:batchx.reshape(1,-1), y_: ys, qst_: qsts,drop:1})\n",
        "\t\t\t\t#print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
        "\t\t\t\taccsum += train_accuracy\n",
        "\t\t\t\tif i % 1000 == 0:\n",
        "\t\t\t\t\tprint(\"steps %d to %d, training accuracy %g\"%(i-1000,i, accsum / 100))\n",
        "\t\t\t\t\taccsum = 0\n",
        "\t\taccsum = 0\n",
        "\t\tfor j in range(75001,80001):\n",
        "\t\t\tys = labelz[j].toarray()\n",
        "\t\t\tqsts = qstz[j].reshape(1,-1)\n",
        "\t\t\tbatchx = (np.swapaxes(dataz[j],0,2))\n",
        "\t\t\tif j % 10 == 0:\n",
        "\t\t\t\t#batch = mnist.train.next_batch(100)\n",
        "\t\t\t\ttrain_accuracy = accuracy.eval(feed_dict={\n",
        "\t\t\t\t\tx:batchx.reshape(1,-1), y_: ys, qst_: qsts,drop:1})\n",
        "\t\t\t\t#print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
        "\t\t\t\taccsum += train_accuracy\n",
        "\t\t\t\tif j % 5000 == 0:\n",
        "\t\t\t\t\tprint(\"Validation Accuracy %g\"%( accsum / 500))\n",
        "\t\t\t\t\taccsum = 0\n",
        "\n",
        "\tfor u in range(80001,85001):\n",
        "\t\t\tys = reltrain[2][u].toarray()\n",
        "\t\t\tqsts = reltrain[1][u].reshape(1,-1)\n",
        "\t\t\tbatchx = (np.swapaxes(reltrain[0][u],0,2))\n",
        "\t\t\tif u % 10 == 0:\n",
        "\t\t\t\t#batch = mnist.train.next_batch(100)\n",
        "\t\t\t\ttrain_accuracy = accuracy.eval(feed_dict={\n",
        "\t\t\t\t\tx:batchx.reshape(1,-1), y_: ys, qst_: qsts,drop:1})\n",
        "\t\t\t\t#print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
        "\t\t\t\taccsum += train_accuracy\n",
        "\t\t\t\tif u % 5000 == 0:\n",
        "\t\t\t\t\tprint(\"Test Ac %g\"%( accsum / 500))\n",
        "\t\t\t\t\taccsum = 0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            "INFO:tensorflow:Restoring parameters from /content/drive/My Drive/RelationalNN/dm1.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFoundError\u001b[0m: 2 root error(s) found.\n  (0) Not found: Key Variable_100 not found in checkpoint\n\t [[{{node save_19/RestoreV2}}]]\n  (1) Not found: Key Variable_100 not found in checkpoint\n\t [[{{node save_19/RestoreV2}}]]\n\t [[save_19/RestoreV2/_51]]\n0 successful operations.\n0 derived errors ignored.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1289\u001b[0m         sess.run(self.saver_def.restore_op_name,\n\u001b[0;32m-> 1290\u001b[0;31m                  {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[1;32m   1291\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1383\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[0;32m-> 1384\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFoundError\u001b[0m: 2 root error(s) found.\n  (0) Not found: Key Variable_100 not found in checkpoint\n\t [[node save_19/RestoreV2 (defined at /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1748) ]]\n  (1) Not found: Key Variable_100 not found in checkpoint\n\t [[node save_19/RestoreV2 (defined at /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1748) ]]\n\t [[save_19/RestoreV2/_51]]\n0 successful operations.\n0 derived errors ignored.\n\nOriginal stack trace for 'save_19/RestoreV2':\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 664, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-27-81e936756ba1>\", line 157, in <module>\n    saver = tf.train.Saver()\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py\", line 828, in __init__\n    self.build()\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py\", line 840, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py\", line 878, in _build\n    build_restore=build_restore)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py\", line 508, in _build_internal\n    restore_sequentially, reshape)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py\", line 328, in _AddRestoreOps\n    restore_sequentially)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py\", line 575, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_io_ops.py\", line 1696, in restore_v2\n    name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py\", line 794, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\", line 3357, in create_op\n    attrs, op_def, compute_device)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\", line 3426, in _create_op_internal\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\", line 1748, in __init__\n    self._traceback = tf_stack.extract_stack()\n",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1299\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1300\u001b[0;31m         \u001b[0mnames_to_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject_graph_key_mapping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1301\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNotFoundError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py\u001b[0m in \u001b[0;36mobject_graph_key_mapping\u001b[0;34m(checkpoint_path)\u001b[0m\n\u001b[1;32m   1617\u001b[0m   \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNewCheckpointReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1618\u001b[0;31m   \u001b[0mobject_graph_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrackable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOBJECT_GRAPH_PROTO_KEY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1619\u001b[0m   \u001b[0mobject_graph_proto\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrackable_object_graph_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrackableObjectGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36mget_tensor\u001b[0;34m(self, tensor_str)\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mCheckpointReader_GetTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFoundError\u001b[0m: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-e514509e648d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'/content/drive/My Drive/RelationalNN/dm1.ckpt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m130\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1304\u001b[0m         \u001b[0;31m# a helpful message (b/110263146)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1305\u001b[0m         raise _wrap_restore_error_with_msg(\n\u001b[0;32m-> 1306\u001b[0;31m             err, \"a Variable name or other graph key that is missing\")\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m       \u001b[0;31m# This is an object-based checkpoint. We'll print a warning and then do\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFoundError\u001b[0m: Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\n2 root error(s) found.\n  (0) Not found: Key Variable_100 not found in checkpoint\n\t [[node save_19/RestoreV2 (defined at /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1748) ]]\n  (1) Not found: Key Variable_100 not found in checkpoint\n\t [[node save_19/RestoreV2 (defined at /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1748) ]]\n\t [[save_19/RestoreV2/_51]]\n0 successful operations.\n0 derived errors ignored.\n\nOriginal stack trace for 'save_19/RestoreV2':\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 664, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-27-81e936756ba1>\", line 157, in <module>\n    saver = tf.train.Saver()\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py\", line 828, in __init__\n    self.build()\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py\", line 840, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py\", line 878, in _build\n    build_restore=build_restore)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py\", line 508, in _build_internal\n    restore_sequentially, reshape)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py\", line 328, in _AddRestoreOps\n    restore_sequentially)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py\", line 575, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_io_ops.py\", line 1696, in restore_v2\n    name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py\", line 794, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\", line 3357, in create_op\n    attrs, op_def, compute_device)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\", line 3426, in _create_op_internal\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\", line 1748, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
          ]
        }
      ]
    }
  ]
}